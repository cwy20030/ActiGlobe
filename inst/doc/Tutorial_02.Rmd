---
title: "Advanced Data Harmonization"
subtitle: "Stream Lining Pre-processing from Daylight Saving to Travel-induced Time Shift"
author: "C. William Yao"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Advanced Data Harmonization}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
pkgdown:
  as_is: true
---

## What will be covered in this tutorial?
This specific tutorial is designed specifically to show users how to use ActiGlobe to preprocess longitudinal actigrpahy recordings affected by time shift. For analysis and generation of graphic/excel report of daily actigraphy measures, please go to other 



```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Load the Libraries
```{r setup}
library(ActiGlobe)

### Optional Library
library(zeallot)
```
If any of the packages has yet been installed, we can always install them using the function ["install.packages()"]. 


## Load Example Data: FlyEast
```{r Load Data, message=FALSE, warning=FALSE}
data("FlyEast")

head(FlyEast)   ### Only the first few lines
```

For more information, type `?FlyEast` or `help(FlyEast)` in your R console.

< Tip for Beginner to R> 
Type: View(FlyEast) in the R console will allow users to review the data structure of FlyEast.



## Step 0. Create a brief summary of the recordings
In general, when pre-processing or harmonizing large volumes of data, it's good practice to first generate a structured summary of the dataset at hand.

Here, we use `BriefSum()` to generate an initial summary of the actigraphy data recorded in FlyEast. Based on the initial recording time, it runs through the raw recording file to provide a quick overview with simple summaries for each recording day and a newly enriched actigraphy data. This pre-processing step also automatically adds time-stamps to the original longitudinal recording. If the original location inherits the practice of daylight saving, `BriefSum()` would also automatically handle any gain or loss in time. By default, `BriefSum()` would allow us to store both the summary and the newly enriched recording data in a data.list.

```{r BriefSum, message=FALSE, warning=FALSE}
BdfList = 
BriefSum(df = FlyEast,
         SR = 1/60,
         Start = "2017-10-24 13:45:00")


str(BdfList,max.level = 1) ### An overview of the output structure from BriefSum()
```

We can also take the advantage of `zeallot` to store multiple outputs at once just like in `Matlab` and `Python`.

```{r eval=FALSE}
c(Bdf, df) %<-%
BriefSum(df = FlyEast,
         SR = 1/60,
         Start = "2017-10-24 13:45:00")
```

In the brief summary of daily recording, we would have thirteen parameters including the information on the beginning and the end of each daily recording period, labels warning the total time of a recording is less than 24 hours and the presence of daylight saving time (based on the initial time zone).

```{r message=FALSE, warning=FALSE}
Bdf <- BdfList$Bdf
head(Bdf)
```

In the enriched data - `df`, we have both the original data stored in `FlyEast` and some new information, such as the time stamp of each data point.

```{r View df, message=FALSE, warning=FALSE}
df <- BdfList$df

head(df) ### This should give us the same first few lines of FlyEast dataset with a few new columns created by [BrifSum()].
```

For longitudinal recordings that did not involve long-distance traveling, we may simply stop here and move onto the estimating cosinor parameters for further analysis. But given that `ActiGlobe` was designed specifically to harmonize and correct recordings affected by changes in the time zone. We have to go a few steps further to clean our data.

## Step 1: Look into a travel diary

While users born after 2YK may not be familiar with concept of a travel diary, it was relatively popular among young travelers to document their journeys while traveling. These physical notebooks generally come with item-wise spaces to jot down our trip itinerary, including date, time and destination. This information is crucial to properly sort out the recordings by day and correct the previously created time stamps by `BriefSum` to match the destination.

Fortunately, we already created something similar for this tutorial - TLog. In the TLog, The `TLog` was created using the standard travel diary template, which can be created using the function `TravelLog()`. For more information on the standard travel diary, type `?TravelLog` or `help(TravelLog)` in the R console.

```{r View TLog, message=FALSE, warning=FALSE}
data(TLog)

head(TLog)
```

This simplified travel diary is essential for pre-processing actigraphy data using `ActiGlobe`. The diary contains five columns to help document the itinerary for each trip that the wearer took. By default, the first row should contain the information about the original location when the recording started. Here, one may notice our intentional design of the template to record UTC_Offset by default, instead of the actual geological location. This strategy aims to reduce the level of intrusiveness that participants may feel when asked to provide details of their trip. Since daylight saving is not always a shared practice for all geological locations within the same time zone or even the same country, it is important to add this information because it can affect up to one hour in difference when correcting for time stamps.

To facilitate the documentation of the travel log, we also include a copy of the standard Internet Assigned Numbers Authority (IANA) time table in ActiGlobe. We can simply use `View(IANA)` to pull up the 2024 version of the time table.

```{r IANA header, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
head(IANA)
```

## Step 2: Adjust time change based on the travel diary

Before `ActiGlobe` directly modify information stored in the enriched longitudinal recording - `df`, we will need to adjust the brief summary stored in `Bdf`. This design allows us to quickly scan through the summary file just in case any adjustment is not properly addressed.

```{r TAdjust}
Bdf.adj = TAdjust(Bdf, TLog)

head(Bdf.adj)
```

##  {.scrollable}

```{r include=FALSE, eval=FALSE}
dk <- Bdf.adj[c("Date","Epoch","UTC","TZ_code","Daylight_Saving","Recording_Start","Recording_End","GL_Offset","nDataPoints","Cumulative_Start_Second","Cumulative_End_Second")]
dk$Cumulative_End_Second2 <- Bdf$Cumulative_End_Second
dk$Cumulative_Start_Second2 <- Bdf$Cumulative_Start_Second

```


When we put it side-by-side against the initial brief summary, we can see clear changes in the various documentations about the recordings and their annotations.

```{r message=FALSE, warning=FALSE, paged.print=TRUE, out.width="30%"}
knitr::kable(Bdf[10:15,]) ### Only display 6 days 

knitr::kable(Bdf.adj[10:15,]) ### Only display 6 days 
```



###  {.scrollable}

When we put it side-by-side against the initial brief summary, we can see clear changes in the various documentations about the recordings and their annotations

```{r Original_Data, message=FALSE, warning=FALSE, fig.height=3, fig.width=8}
ggActiGlobe(df = df, 
            Bdf = Bdf,
            VAct = "Activity",
            VDT = "DateTime")
```


```{r Pre-processed_Data, message=FALSE, warning=FALSE, fig.height=3, fig.width=8}
### Reconstruct the longitudinal recording with proper segmentation
dfList = Act2Daily(df = df,
          Bdf = Bdf.adj,
          VAct = "Activity",
          VTm = "Time",
          Incomplete = TRUE,
          Travel = TRUE)

df2 <- do.call(rbind, dfList$Daily_df)

ggActiGlobe(df = df2, 
               Bdf = Bdf.adj,
               VAct = "Activity",
               VDT = "DateTime")
```


We can also use the following code to look at each daily recording separately. Note that the code below was intentionally left without generating any output plot to avoid overcrowding this tutorial.

1. Unadjusted Original Recording
```{r Original Daily, eval=FALSE, fig.height=5, fig.width=7}

for(i in 1:length(x)) {
x <- Bdf$Cumulative_Start_Second  
y <- Bdf$Cumulative_End_Second  
GX <- df$Activity[(x[i]:y[i])/60]
print(plot(GX,main = i, font.lab = 2,ylab = "Activity (counts)"))
  
}

```

2. Time-shift Adjusted Recording
```{r Adjusted Daily, eval=FALSE, fig.height=5, fig.width=7}

for(i in 1:length(x)) {
x <- Bdf.adj$Cumulative_Start_Second  
y <- Bdf.adj$Cumulative_End_Second  
GX <- df$Activity[(x[i]:y[i])/60]
print(plot(GX,main = i, font.lab = 2,ylab = "Activity (counts)"))
  
}
```

3. Time-shift Adjusted Recording
```{r Automated Split Data, eval=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
for(i in names(dfList$Daily_df)) {
  
  plot(dfList$Daily_df[[i]]$Activity, main = i, font.lab = 2,ylab = "Activity (counts)")
  
}
```

See the next tutorial for how to segment/export recordings by day and how to generate graphic report.
